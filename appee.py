# -*- coding: utf-8 -*-
"""appEE

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L-Et32GYnEh0h-z0mzehIJz-Y_reGLq2
"""

import streamlit as st

import telepot
import requests
import json
import re
from bs4 import BeautifulSoup
import time

def extraer_articulo(url):
  try:
    r1 = requests.get(url)
    coverpage = r1.content
    soup1 = BeautifulSoup(coverpage, 'html5lib')
    #This part concerns the html part we are looking for, but we'll have some troubles into it, because we'll find a javascript structure containing our goal data
    coverpage_news = soup1.find('script', id="fusion-metadata", type="application/javascript")
    coverpage_newsString = coverpage_news.string
    def find_json_objects(text: str, decoder=json.JSONDecoder()):
      """Find JSON objects in text, and generate decoded JSON data"""
      pos = 0
      while True:
          match = text.find("{", pos)
          if match == -1:
              break
          try:
              result, index = decoder.raw_decode(text[match:])
              yield result
              pos = match + index
          except ValueError:
              pos = match + 1
    # Creating a list with the result got by find_json function to easily navigate into it
    listCoverpageNewsString = list(find_json_objects(coverpage_newsString))

    #We detect our Key Error identifying the pattern the list have at the time of looking for our data on an ordered way. Everything is kept in a python list through
    #the append methodm taking into account the variation of data into the json format
    articleComplete = []
    contentArt = listCoverpageNewsString[1]['content_elements']
    count = 0
    for microContent in contentArt[0:len(contentArt)]:
      try:
        part = listCoverpageNewsString[1]['content_elements'][count]['content']
        articleComplete.append(part)
      except KeyError:
        pass
      count = 1 + count

    #Becoming everything into a string
    articleString = ''
    count = 0
    for art in articleComplete[0:len(articleComplete)]:
      part = articleComplete[count]
      articleString = articleString + '\n\n'+ part
      count += 1
    # Getting additional information of our main soup (soup1)
    coverpage_newsTitle = soup1.find('title')
    titulo = coverpage_newsTitle.get_text()
    subtitle = soup1.find_all('meta')[1]['content']
    linkUrl = soup1.find_all('link')[7]['href']
    author= soup1.find('h3', class_="ACredit-Author").get_text()
    date = soup1.find('div', class_="Datetime ArticleHeader-Date").get_text()
    # Collecting all data into a string
    contenido = 'Por: '+ author + '\n' + subtitle + '\n' + linkUrl + '\n' + date + '\n' + articleString

    completeArticle = titulo + '\n' + 'Por: '+ author + '\n' + subtitle + '\n' + linkUrl + '\n' + date + '\n' + articleString
    token = '5541258900:AAE0PhrKqTjHMWk3-ZdePgzrgRJiB3hv5CI' # telegram token
    receiver_id = 582395721 # https://api.telegram.org/bot<TOKEN>/getUpdates


    bot = telepot.Bot(token)

    if len(completeArticle) > 4096:
        for x in range(0, len(completeArticle), 4096):
            bot.sendMessage(receiver_id, completeArticle[x:x+4096])
    else:
        bot.sendMessage(receiver_id, completeArticle)


    return titulo, contenido

  except Exception as e:
    return None, f"Error: {str(e)}"

# Configuraci칩n de la p치gina
st.set_page_config(
    page_title="Extractor de Art칤culos",
    page_icon="游닗",
    layout="wide"
)

# Inicializar estado de sesi칩n
if 'mostrar_formulario' not in st.session_state:
    st.session_state.mostrar_formulario = True
if 'resultados' not in st.session_state:
    st.session_state.resultados = None

# Funci칩n para extraer art칤culo
def extraer_articulo_callback():
    url = st.session_state.url_input
    if url:
        with st.spinner("Extrayendo contenido..."):
            titulo, contenido = extraer_articulo(url)  # Llamamos a la funci칩n importada

        if titulo:
            st.session_state.resultados = {
                "titulo": titulo,
                "contenido": contenido,
                "url": url
            }
            st.session_state.mostrar_formulario = False
        else:
            st.error(contenido)  # Muestra el mensaje de error
    else:
        st.warning("Por favor ingresa una URL v치lida")

# Funci칩n para reiniciar y mostrar el formulario
def reiniciar():
    st.session_state.mostrar_formulario = True
    st.session_state.resultados = None
    st.experimental_rerun()

# Interfaz principal
st.title("游닗 Extractor de Art칤culos de Peri칩dicos")

# Mostrar formulario solo si est치 activo
if st.session_state.mostrar_formulario:
    st.markdown("Ingresa la URL del art칤culo que deseas extraer")

    # Input de URL
    st.text_input(
        "URL del art칤culo",
        key="url_input",
        placeholder="https://www.ejemplo.com/articulo/123",
        help="Ingresa la URL completa del art칤culo"
    )

    # Bot칩n de extracci칩n
    st.button("Extraer Art칤culo", type="primary", on_click=extraer_articulo_callback)

# Mostrar resultados si existen
elif st.session_state.resultados:
    # Mostrar t칤tulo
    st.header(st.session_state.resultados["titulo"])
    st.markdown(f"**URL:** {st.session_state.resultados['url']}")

    # Mostrar contenido
    st.subheader("Contenido del art칤culo")
    st.text_area(
        "",
        st.session_state.resultados["contenido"],
        height=400,
        label_visibility="collapsed"
    )

    # Botones
    col1, col2 = st.columns([1, 1])

    with col1:
        # Bot칩n de descarga
        st.download_button(
            label="Descargar art칤culo",
            data=f"{st.session_state.resultados['titulo']}\n\n{st.session_state.resultados['contenido']}",
            file_name=f"articulo_{st.session_state.resultados['titulo'][:20].replace(' ', '_')}.txt",
            mime="text/plain"
        )

    with col2:
        # Bot칩n para extraer otro art칤culo
        st.button("Extraer otro art칤culo", on_click=reiniciar)

# Sidebar con informaci칩n
st.sidebar.header("Acerca de")
st.sidebar.info("""
Esta aplicaci칩n extrae contenido de art칤culos de peri칩dicos.
Aseg칰rate de tener permiso para acceder al contenido.
""")

# Footer
st.markdown("---")
st.markdown("丘멆잺 **Nota:** Esta herramienta es para uso personal. Respeta los t칠rminos de servicio de los sitios web.")